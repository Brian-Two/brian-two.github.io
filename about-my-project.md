## About My Project

AI Robot Autonomy with Deep Learning 


Problem

There is a lack of research focusing on exploring ways to build educational software that integrates physical robots and physiological sensors. Addressing this gap can lead to innovative solutions that enhance the interaction between humans and robots, especially for applications requiring autonomy and real-time data processing.

Approach

During this project, I will assist a team in designing a system that accomplishes the following:

	•	Capture physiological data such as EEG and EMG from the human body.
	•	Process raw sensor data and classify events such as gestures (e.g., arm movements) and emotional states (e.g., attention levels).
	•	Map output from physiological sensors to a physical robot, ensuring accurate and responsive interaction between the human and the robot.

The overall goal for the project is to design a wheelchair using principles of Robot Autonomy, such as:

	•	Classification: Identifying and categorizing various physiological signals to interpret human intentions and actions.
	•	Segmentation: Dividing sensor data into meaningful segments for more precise analysis and response.
	•	Object Detection: Recognizing and locating objects in the wheelchair’s environment to navigate safely and efficiently.

Expected Outcome

The project is expected to result in a conference poster presentation at the end of the DREU program. The poster will focus on the system’s technical architecture, showcasing how the integration of deep learning techniques and physiological data can enhance robot autonomy in real-world applications.


