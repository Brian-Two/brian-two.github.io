## About My Project

AI Robot Autonomy with Deep Learning 


**Problem**

There is a lack of research focusing on exploring ways to build educational software that integrates physical robots and physiological sensors. Addressing this gap can lead to innovative solutions that enhance the interaction between humans and robots, especially for applications requiring autonomy and real-time data processing.



The overall goal for the project is to design a wheelchair using principles of Robot Autonomy, such as:

- Classification: Identifying and categorizing various physiological signals to interpret human intentions and actions.
- Segmentation: Dividing sensor data into meaningful segments for more precise analysis and response.
- Object Detection: Recognizing and locating objects in the wheelchair’s environment to navigate safely and efficiently.

**Expected Outcome**

Our project aims to develop an autonomous wheelchair capable of navigating complex environments like airports, utilizing both Visual SLAM (Simultaneous Localization and Mapping) and a track-based approach for enhanced mobility and localization. The integration of a RealSense camera and IMU enables the wheelchair to create detailed maps of its surroundings while continuously tracking its position. The use of deep learning techniques for classification, segmentation, and object detection further enhances the wheelchair’s autonomy and navigation capabilities. Our innovative system not only improves the independence and mobility of disabled individuals but also demonstrates the potential for advanced human-robot interaction in real-world applications.


